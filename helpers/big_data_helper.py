import polars as pl
import os
import tempfile
import shutil
from pathlib import Path


def process_in_batches(lazy_df: pl.LazyFrame, sort_column: str, batch_func, output_dir: str, batch_size: int = 100_000):
    # –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫
    total_rows = lazy_df.collect().height
    offset = 0
    batch_idx = 0
    
    while offset < total_rows:
        # –í—ã—Ä–µ–∑–∞–µ–º —Ç–µ–∫—É—â–∏–π –±–∞—Ç—á –ø–æ —Å—Ä–µ–∑—É
        batch_df = lazy_df.slice(offset, batch_size).collect()
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
        processed = batch_func(batch_df)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        filename = os.path.join(output_dir, f"batch_{batch_idx}.parquet")
        processed.write_parquet(filename)
        # –ì–æ—Ç–æ–≤–∏–º—Å—è –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–∞—Ç—á—É
        offset += batch_size
        batch_idx += 1

        
def merge_parquet_files(input_dir: str, output_file: str):
    # –°–æ–±–∏—Ä–∞–µ–º –ø—É—Ç–∏ –∫–æ –≤—Å–µ–º parquet-—Ñ–∞–π–ª–∞–º –≤ –ø–∞–ø–∫–µ
    parquet_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(".parquet")]
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ parquet-—Ñ–∞–π–ª—ã –ª–µ–Ω–∏–≤–æ (LazyFrame)
    lazy_frames = [pl.scan_parquet(f) for f in parquet_files]
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ LazyFrames –≤ –æ–¥–∏–Ω
    combined_lazy = pl.concat(lazy_frames)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ DataFrame –∏ —Å—Ä–∞–∑—É –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª

    combined_lazy.collect().write_parquet(output_file)
    

def apply_function_by_batch(input_path, output_path , fun, column_filtration, batch_size = 10_000_000):
    data = pl.scan_parquet(input_path)

    # —Å–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)

        # –ø—É—Ç—å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
        output_dir = tmp_path / "tmp"
        output_dir.mkdir(parents=True, exist_ok=True)

        # –≤—ã–ø–æ–ª–Ω—è–µ–º –±–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫—É
        process_in_batches(
            data,
            column_filtration,
            fun,
            str(output_dir),
            batch_size=10_000_000,
        )

        # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ
        merged_path = tmp_path / "tmp.parquet"
        merge_parquet_files(str(output_dir), str(merged_path))

        # –ø–µ—Ä–µ–Ω–æ—Å–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—É–¥–∞ –Ω—É–∂–Ω–æ
        shutil.move(str(merged_path), output_path)

    # tmpdir –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–∏—Ç—Å—è –∑–¥–µ—Å—å


def estimate_parquet_ram_usage(path: str, sample_rows: int = 10_000):
    print(f"\nüìÅ –§–∞–π–ª: {path}")
    print(f"üìä –°—ç–º–ø–ª —Å—Ç—Ä–æ–∫: {sample_rows:,}")

    # —á–∏—Ç–∞–µ–º sample
    df_sample = pl.read_parquet(path, n_rows=sample_rows)
    size_sample = df_sample.estimated_size()
    print(f"üîπ –†–∞–∑–º–µ—Ä sample: {size_sample/1024**2:.2f} MB")

    # –ª–µ–Ω–∏–≤–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Å—Ç—Ä–æ–∫
    lf = pl.scan_parquet(path)
    total_rows = lf.select(pl.len()).collect().item()
    print(f"üîπ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ: {total_rows:,}")

    # –æ—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    estimated_total_bytes = size_sample * (total_rows / sample_rows)
    estimated_total_gb = estimated_total_bytes / 1024**3

    print(f"\nüìê –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–±—ä—ë–º–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–º—è—Ç–∏: {estimated_total_gb:.2f} GB")



# Polars –Ω–µ —É–º–µ–µ—Ç –∫–∞–∫ pandas —Å—Ç—ã–∫–∞–æ–≤–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ, –µ–º—É –Ω—É–∂–Ω–æ —Å—Ç—Ä–æ–≥–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
def concat_files(lf1_path, lf2_path, result_path):
    lf1 = pl.scan_parquet(lf1_path)
    lf2 = pl.scan_parquet(lf2_path)
    
    lf1_cols = lf1.collect_schema().names()
    lf2_cols = lf2.collect_schema().names()

    # –ü—Ä–∏–º–µ—Ä: –ø—Ä–∏–≤–µ—Å—Ç–∏ –ø–æ—Ä—è–¥–æ–∫ –∏ –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∫ lf1
    lf2_aligned = lf2.select(
        [pl.col(c) if c in lf2_cols else pl.lit(None).alias(c) for c in lf1_cols]
    )

    lf = pl.concat([lf1, lf2_aligned])
    
    lf.sink_parquet(result_path)
